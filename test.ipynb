{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Constants\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = 64, 64\n",
    "SEQUENCE_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def frames_extractor(video_path):\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    for frame_counter in range(0, video_frames_count, skip_frames_window):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "        success, frame = video_reader.read()\n",
    "        if not success:\n",
    "            break\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            x, y, w, h = faces[0]\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            resized_face = cv2.resize(face, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "            normalized_face = resized_face / 255.0\n",
    "            frames_list.append(normalized_face)\n",
    " \n",
    "       # Stop if we have collected enough frames\n",
    "        if len(frames_list) >= SEQUENCE_LENGTH:\n",
    "            break\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "    while len(frames_list) < SEQUENCE_LENGTH:\n",
    "        frames_list.append(np.zeros((IMAGE_HEIGHT, IMAGE_WIDTH, 3)))  \n",
    "\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def create_dataset(root_dir, classes_list):\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        \n",
    "        files_list = os.listdir(class_dir)\n",
    "\n",
    "        for file_name in files_list:\n",
    "            video_file_path = os.path.join(class_dir, file_name)\n",
    "            \n",
    "            frames = frames_extractor(video_file_path)\n",
    "            \n",
    "            # Check if the extracted frames match the SEQUENCE_LENGTH\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return features, labels, video_files_paths\n",
    "\n",
    "# Set your root directory and classes list\n",
    "DATASET_DIR = \"C:\\\\Users\\\\bhatt\\\\Machine Learning\\\\DeepTrace\\\\celebDataset\"\n",
    "CLASSES_LIST = [\"real\", \"synthetic\"]\n",
    "\n",
    "\n",
    "features, labels, video_files_paths = create_dataset(DATASET_DIR, CLASSES_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim):\n",
    "        super(TemporalAttention, self).__init__()\n",
    "        self.fc1 = nn.Linear(feature_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "      \n",
    "        u = torch.tanh(self.fc1(x))  \n",
    "        a = torch.softmax(self.fc2(u), dim=1)  \n",
    "        x_attended = (a * x).sum(dim=1)  \n",
    "        return x_attended\n",
    "\n",
    "class EfficientNetTemporalAttentionModel(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_dim=128):\n",
    "        super(EfficientNetTemporalAttentionModel, self).__init__()\n",
    "        \n",
    "        efficientnet = models.efficientnet_b0(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(efficientnet.children())[:-1])\n",
    "        feature_dim = efficientnet.classifier[1].in_features\n",
    "        \n",
    "        self.temporal_attention = TemporalAttention(feature_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(feature_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_frames, channels, height, width = x.size()\n",
    "        \n",
    "        x = x.view(batch_size * num_frames, channels, height, width)  \n",
    "        features = self.feature_extractor(x)  \n",
    "        features = features.view(batch_size, num_frames, -1)  \n",
    "        attended_features = self.temporal_attention(features)\n",
    "\n",
    "        output = self.fc(attended_features)\n",
    "        return output\n",
    "\n",
    "\n",
    "num_classes = len(CLASSES_LIST)\n",
    "model = EfficientNetTemporalAttentionModel(num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetTemporalAttentionModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "              (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (2): Conv2dNormActivation(\n",
      "              (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
      "              (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "              (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
      "        )\n",
      "        (2): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "              (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
      "        )\n",
      "        (2): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "              (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
      "        )\n",
      "        (1): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
      "        )\n",
      "        (2): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
      "        )\n",
      "        (3): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): MBConv(\n",
      "          (block): Sequential(\n",
      "            (0): Conv2dNormActivation(\n",
      "              (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (1): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "              (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): SiLU(inplace=True)\n",
      "            )\n",
      "            (2): SqueezeExcitation(\n",
      "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (activation): SiLU(inplace=True)\n",
      "              (scale_activation): Sigmoid()\n",
      "            )\n",
      "            (3): Conv2dNormActivation(\n",
      "              (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
      "        )\n",
      "      )\n",
      "      (8): Conv2dNormActivation(\n",
      "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (temporal_attention): TemporalAttention(\n",
      "    (fc1): Linear(in_features=1280, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=1280, out_features=2, bias=True)\n",
      ")\n",
      "Output shape: torch.Size([2, 2])\n",
      "\n",
      "Model Weights Shapes:\n",
      "\n",
      "EfficientNet Feature Extractor Layers:\n",
      "0.0.0.weight shape: torch.Size([32, 3, 3, 3])\n",
      "0.0.1.weight shape: torch.Size([32])\n",
      "0.0.1.bias shape: torch.Size([32])\n",
      "0.1.0.block.0.0.weight shape: torch.Size([32, 1, 3, 3])\n",
      "0.1.0.block.0.1.weight shape: torch.Size([32])\n",
      "0.1.0.block.0.1.bias shape: torch.Size([32])\n",
      "0.1.0.block.1.fc1.weight shape: torch.Size([8, 32, 1, 1])\n",
      "0.1.0.block.1.fc1.bias shape: torch.Size([8])\n",
      "0.1.0.block.1.fc2.weight shape: torch.Size([32, 8, 1, 1])\n",
      "0.1.0.block.1.fc2.bias shape: torch.Size([32])\n",
      "0.1.0.block.2.0.weight shape: torch.Size([16, 32, 1, 1])\n",
      "0.1.0.block.2.1.weight shape: torch.Size([16])\n",
      "0.1.0.block.2.1.bias shape: torch.Size([16])\n",
      "0.2.0.block.0.0.weight shape: torch.Size([96, 16, 1, 1])\n",
      "0.2.0.block.0.1.weight shape: torch.Size([96])\n",
      "0.2.0.block.0.1.bias shape: torch.Size([96])\n",
      "0.2.0.block.1.0.weight shape: torch.Size([96, 1, 3, 3])\n",
      "0.2.0.block.1.1.weight shape: torch.Size([96])\n",
      "0.2.0.block.1.1.bias shape: torch.Size([96])\n",
      "0.2.0.block.2.fc1.weight shape: torch.Size([4, 96, 1, 1])\n",
      "0.2.0.block.2.fc1.bias shape: torch.Size([4])\n",
      "0.2.0.block.2.fc2.weight shape: torch.Size([96, 4, 1, 1])\n",
      "0.2.0.block.2.fc2.bias shape: torch.Size([96])\n",
      "0.2.0.block.3.0.weight shape: torch.Size([24, 96, 1, 1])\n",
      "0.2.0.block.3.1.weight shape: torch.Size([24])\n",
      "0.2.0.block.3.1.bias shape: torch.Size([24])\n",
      "0.2.1.block.0.0.weight shape: torch.Size([144, 24, 1, 1])\n",
      "0.2.1.block.0.1.weight shape: torch.Size([144])\n",
      "0.2.1.block.0.1.bias shape: torch.Size([144])\n",
      "0.2.1.block.1.0.weight shape: torch.Size([144, 1, 3, 3])\n",
      "0.2.1.block.1.1.weight shape: torch.Size([144])\n",
      "0.2.1.block.1.1.bias shape: torch.Size([144])\n",
      "0.2.1.block.2.fc1.weight shape: torch.Size([6, 144, 1, 1])\n",
      "0.2.1.block.2.fc1.bias shape: torch.Size([6])\n",
      "0.2.1.block.2.fc2.weight shape: torch.Size([144, 6, 1, 1])\n",
      "0.2.1.block.2.fc2.bias shape: torch.Size([144])\n",
      "0.2.1.block.3.0.weight shape: torch.Size([24, 144, 1, 1])\n",
      "0.2.1.block.3.1.weight shape: torch.Size([24])\n",
      "0.2.1.block.3.1.bias shape: torch.Size([24])\n",
      "0.3.0.block.0.0.weight shape: torch.Size([144, 24, 1, 1])\n",
      "0.3.0.block.0.1.weight shape: torch.Size([144])\n",
      "0.3.0.block.0.1.bias shape: torch.Size([144])\n",
      "0.3.0.block.1.0.weight shape: torch.Size([144, 1, 5, 5])\n",
      "0.3.0.block.1.1.weight shape: torch.Size([144])\n",
      "0.3.0.block.1.1.bias shape: torch.Size([144])\n",
      "0.3.0.block.2.fc1.weight shape: torch.Size([6, 144, 1, 1])\n",
      "0.3.0.block.2.fc1.bias shape: torch.Size([6])\n",
      "0.3.0.block.2.fc2.weight shape: torch.Size([144, 6, 1, 1])\n",
      "0.3.0.block.2.fc2.bias shape: torch.Size([144])\n",
      "0.3.0.block.3.0.weight shape: torch.Size([40, 144, 1, 1])\n",
      "0.3.0.block.3.1.weight shape: torch.Size([40])\n",
      "0.3.0.block.3.1.bias shape: torch.Size([40])\n",
      "0.3.1.block.0.0.weight shape: torch.Size([240, 40, 1, 1])\n",
      "0.3.1.block.0.1.weight shape: torch.Size([240])\n",
      "0.3.1.block.0.1.bias shape: torch.Size([240])\n",
      "0.3.1.block.1.0.weight shape: torch.Size([240, 1, 5, 5])\n",
      "0.3.1.block.1.1.weight shape: torch.Size([240])\n",
      "0.3.1.block.1.1.bias shape: torch.Size([240])\n",
      "0.3.1.block.2.fc1.weight shape: torch.Size([10, 240, 1, 1])\n",
      "0.3.1.block.2.fc1.bias shape: torch.Size([10])\n",
      "0.3.1.block.2.fc2.weight shape: torch.Size([240, 10, 1, 1])\n",
      "0.3.1.block.2.fc2.bias shape: torch.Size([240])\n",
      "0.3.1.block.3.0.weight shape: torch.Size([40, 240, 1, 1])\n",
      "0.3.1.block.3.1.weight shape: torch.Size([40])\n",
      "0.3.1.block.3.1.bias shape: torch.Size([40])\n",
      "0.4.0.block.0.0.weight shape: torch.Size([240, 40, 1, 1])\n",
      "0.4.0.block.0.1.weight shape: torch.Size([240])\n",
      "0.4.0.block.0.1.bias shape: torch.Size([240])\n",
      "0.4.0.block.1.0.weight shape: torch.Size([240, 1, 3, 3])\n",
      "0.4.0.block.1.1.weight shape: torch.Size([240])\n",
      "0.4.0.block.1.1.bias shape: torch.Size([240])\n",
      "0.4.0.block.2.fc1.weight shape: torch.Size([10, 240, 1, 1])\n",
      "0.4.0.block.2.fc1.bias shape: torch.Size([10])\n",
      "0.4.0.block.2.fc2.weight shape: torch.Size([240, 10, 1, 1])\n",
      "0.4.0.block.2.fc2.bias shape: torch.Size([240])\n",
      "0.4.0.block.3.0.weight shape: torch.Size([80, 240, 1, 1])\n",
      "0.4.0.block.3.1.weight shape: torch.Size([80])\n",
      "0.4.0.block.3.1.bias shape: torch.Size([80])\n",
      "0.4.1.block.0.0.weight shape: torch.Size([480, 80, 1, 1])\n",
      "0.4.1.block.0.1.weight shape: torch.Size([480])\n",
      "0.4.1.block.0.1.bias shape: torch.Size([480])\n",
      "0.4.1.block.1.0.weight shape: torch.Size([480, 1, 3, 3])\n",
      "0.4.1.block.1.1.weight shape: torch.Size([480])\n",
      "0.4.1.block.1.1.bias shape: torch.Size([480])\n",
      "0.4.1.block.2.fc1.weight shape: torch.Size([20, 480, 1, 1])\n",
      "0.4.1.block.2.fc1.bias shape: torch.Size([20])\n",
      "0.4.1.block.2.fc2.weight shape: torch.Size([480, 20, 1, 1])\n",
      "0.4.1.block.2.fc2.bias shape: torch.Size([480])\n",
      "0.4.1.block.3.0.weight shape: torch.Size([80, 480, 1, 1])\n",
      "0.4.1.block.3.1.weight shape: torch.Size([80])\n",
      "0.4.1.block.3.1.bias shape: torch.Size([80])\n",
      "0.4.2.block.0.0.weight shape: torch.Size([480, 80, 1, 1])\n",
      "0.4.2.block.0.1.weight shape: torch.Size([480])\n",
      "0.4.2.block.0.1.bias shape: torch.Size([480])\n",
      "0.4.2.block.1.0.weight shape: torch.Size([480, 1, 3, 3])\n",
      "0.4.2.block.1.1.weight shape: torch.Size([480])\n",
      "0.4.2.block.1.1.bias shape: torch.Size([480])\n",
      "0.4.2.block.2.fc1.weight shape: torch.Size([20, 480, 1, 1])\n",
      "0.4.2.block.2.fc1.bias shape: torch.Size([20])\n",
      "0.4.2.block.2.fc2.weight shape: torch.Size([480, 20, 1, 1])\n",
      "0.4.2.block.2.fc2.bias shape: torch.Size([480])\n",
      "0.4.2.block.3.0.weight shape: torch.Size([80, 480, 1, 1])\n",
      "0.4.2.block.3.1.weight shape: torch.Size([80])\n",
      "0.4.2.block.3.1.bias shape: torch.Size([80])\n",
      "0.5.0.block.0.0.weight shape: torch.Size([480, 80, 1, 1])\n",
      "0.5.0.block.0.1.weight shape: torch.Size([480])\n",
      "0.5.0.block.0.1.bias shape: torch.Size([480])\n",
      "0.5.0.block.1.0.weight shape: torch.Size([480, 1, 5, 5])\n",
      "0.5.0.block.1.1.weight shape: torch.Size([480])\n",
      "0.5.0.block.1.1.bias shape: torch.Size([480])\n",
      "0.5.0.block.2.fc1.weight shape: torch.Size([20, 480, 1, 1])\n",
      "0.5.0.block.2.fc1.bias shape: torch.Size([20])\n",
      "0.5.0.block.2.fc2.weight shape: torch.Size([480, 20, 1, 1])\n",
      "0.5.0.block.2.fc2.bias shape: torch.Size([480])\n",
      "0.5.0.block.3.0.weight shape: torch.Size([112, 480, 1, 1])\n",
      "0.5.0.block.3.1.weight shape: torch.Size([112])\n",
      "0.5.0.block.3.1.bias shape: torch.Size([112])\n",
      "0.5.1.block.0.0.weight shape: torch.Size([672, 112, 1, 1])\n",
      "0.5.1.block.0.1.weight shape: torch.Size([672])\n",
      "0.5.1.block.0.1.bias shape: torch.Size([672])\n",
      "0.5.1.block.1.0.weight shape: torch.Size([672, 1, 5, 5])\n",
      "0.5.1.block.1.1.weight shape: torch.Size([672])\n",
      "0.5.1.block.1.1.bias shape: torch.Size([672])\n",
      "0.5.1.block.2.fc1.weight shape: torch.Size([28, 672, 1, 1])\n",
      "0.5.1.block.2.fc1.bias shape: torch.Size([28])\n",
      "0.5.1.block.2.fc2.weight shape: torch.Size([672, 28, 1, 1])\n",
      "0.5.1.block.2.fc2.bias shape: torch.Size([672])\n",
      "0.5.1.block.3.0.weight shape: torch.Size([112, 672, 1, 1])\n",
      "0.5.1.block.3.1.weight shape: torch.Size([112])\n",
      "0.5.1.block.3.1.bias shape: torch.Size([112])\n",
      "0.5.2.block.0.0.weight shape: torch.Size([672, 112, 1, 1])\n",
      "0.5.2.block.0.1.weight shape: torch.Size([672])\n",
      "0.5.2.block.0.1.bias shape: torch.Size([672])\n",
      "0.5.2.block.1.0.weight shape: torch.Size([672, 1, 5, 5])\n",
      "0.5.2.block.1.1.weight shape: torch.Size([672])\n",
      "0.5.2.block.1.1.bias shape: torch.Size([672])\n",
      "0.5.2.block.2.fc1.weight shape: torch.Size([28, 672, 1, 1])\n",
      "0.5.2.block.2.fc1.bias shape: torch.Size([28])\n",
      "0.5.2.block.2.fc2.weight shape: torch.Size([672, 28, 1, 1])\n",
      "0.5.2.block.2.fc2.bias shape: torch.Size([672])\n",
      "0.5.2.block.3.0.weight shape: torch.Size([112, 672, 1, 1])\n",
      "0.5.2.block.3.1.weight shape: torch.Size([112])\n",
      "0.5.2.block.3.1.bias shape: torch.Size([112])\n",
      "0.6.0.block.0.0.weight shape: torch.Size([672, 112, 1, 1])\n",
      "0.6.0.block.0.1.weight shape: torch.Size([672])\n",
      "0.6.0.block.0.1.bias shape: torch.Size([672])\n",
      "0.6.0.block.1.0.weight shape: torch.Size([672, 1, 5, 5])\n",
      "0.6.0.block.1.1.weight shape: torch.Size([672])\n",
      "0.6.0.block.1.1.bias shape: torch.Size([672])\n",
      "0.6.0.block.2.fc1.weight shape: torch.Size([28, 672, 1, 1])\n",
      "0.6.0.block.2.fc1.bias shape: torch.Size([28])\n",
      "0.6.0.block.2.fc2.weight shape: torch.Size([672, 28, 1, 1])\n",
      "0.6.0.block.2.fc2.bias shape: torch.Size([672])\n",
      "0.6.0.block.3.0.weight shape: torch.Size([192, 672, 1, 1])\n",
      "0.6.0.block.3.1.weight shape: torch.Size([192])\n",
      "0.6.0.block.3.1.bias shape: torch.Size([192])\n",
      "0.6.1.block.0.0.weight shape: torch.Size([1152, 192, 1, 1])\n",
      "0.6.1.block.0.1.weight shape: torch.Size([1152])\n",
      "0.6.1.block.0.1.bias shape: torch.Size([1152])\n",
      "0.6.1.block.1.0.weight shape: torch.Size([1152, 1, 5, 5])\n",
      "0.6.1.block.1.1.weight shape: torch.Size([1152])\n",
      "0.6.1.block.1.1.bias shape: torch.Size([1152])\n",
      "0.6.1.block.2.fc1.weight shape: torch.Size([48, 1152, 1, 1])\n",
      "0.6.1.block.2.fc1.bias shape: torch.Size([48])\n",
      "0.6.1.block.2.fc2.weight shape: torch.Size([1152, 48, 1, 1])\n",
      "0.6.1.block.2.fc2.bias shape: torch.Size([1152])\n",
      "0.6.1.block.3.0.weight shape: torch.Size([192, 1152, 1, 1])\n",
      "0.6.1.block.3.1.weight shape: torch.Size([192])\n",
      "0.6.1.block.3.1.bias shape: torch.Size([192])\n",
      "0.6.2.block.0.0.weight shape: torch.Size([1152, 192, 1, 1])\n",
      "0.6.2.block.0.1.weight shape: torch.Size([1152])\n",
      "0.6.2.block.0.1.bias shape: torch.Size([1152])\n",
      "0.6.2.block.1.0.weight shape: torch.Size([1152, 1, 5, 5])\n",
      "0.6.2.block.1.1.weight shape: torch.Size([1152])\n",
      "0.6.2.block.1.1.bias shape: torch.Size([1152])\n",
      "0.6.2.block.2.fc1.weight shape: torch.Size([48, 1152, 1, 1])\n",
      "0.6.2.block.2.fc1.bias shape: torch.Size([48])\n",
      "0.6.2.block.2.fc2.weight shape: torch.Size([1152, 48, 1, 1])\n",
      "0.6.2.block.2.fc2.bias shape: torch.Size([1152])\n",
      "0.6.2.block.3.0.weight shape: torch.Size([192, 1152, 1, 1])\n",
      "0.6.2.block.3.1.weight shape: torch.Size([192])\n",
      "0.6.2.block.3.1.bias shape: torch.Size([192])\n",
      "0.6.3.block.0.0.weight shape: torch.Size([1152, 192, 1, 1])\n",
      "0.6.3.block.0.1.weight shape: torch.Size([1152])\n",
      "0.6.3.block.0.1.bias shape: torch.Size([1152])\n",
      "0.6.3.block.1.0.weight shape: torch.Size([1152, 1, 5, 5])\n",
      "0.6.3.block.1.1.weight shape: torch.Size([1152])\n",
      "0.6.3.block.1.1.bias shape: torch.Size([1152])\n",
      "0.6.3.block.2.fc1.weight shape: torch.Size([48, 1152, 1, 1])\n",
      "0.6.3.block.2.fc1.bias shape: torch.Size([48])\n",
      "0.6.3.block.2.fc2.weight shape: torch.Size([1152, 48, 1, 1])\n",
      "0.6.3.block.2.fc2.bias shape: torch.Size([1152])\n",
      "0.6.3.block.3.0.weight shape: torch.Size([192, 1152, 1, 1])\n",
      "0.6.3.block.3.1.weight shape: torch.Size([192])\n",
      "0.6.3.block.3.1.bias shape: torch.Size([192])\n",
      "0.7.0.block.0.0.weight shape: torch.Size([1152, 192, 1, 1])\n",
      "0.7.0.block.0.1.weight shape: torch.Size([1152])\n",
      "0.7.0.block.0.1.bias shape: torch.Size([1152])\n",
      "0.7.0.block.1.0.weight shape: torch.Size([1152, 1, 3, 3])\n",
      "0.7.0.block.1.1.weight shape: torch.Size([1152])\n",
      "0.7.0.block.1.1.bias shape: torch.Size([1152])\n",
      "0.7.0.block.2.fc1.weight shape: torch.Size([48, 1152, 1, 1])\n",
      "0.7.0.block.2.fc1.bias shape: torch.Size([48])\n",
      "0.7.0.block.2.fc2.weight shape: torch.Size([1152, 48, 1, 1])\n",
      "0.7.0.block.2.fc2.bias shape: torch.Size([1152])\n",
      "0.7.0.block.3.0.weight shape: torch.Size([320, 1152, 1, 1])\n",
      "0.7.0.block.3.1.weight shape: torch.Size([320])\n",
      "0.7.0.block.3.1.bias shape: torch.Size([320])\n",
      "0.8.0.weight shape: torch.Size([1280, 320, 1, 1])\n",
      "0.8.1.weight shape: torch.Size([1280])\n",
      "0.8.1.bias shape: torch.Size([1280])\n",
      "\n",
      "Temporal Attention Layers:\n",
      "fc1.weight shape: torch.Size([128, 1280])\n",
      "fc1.bias shape: torch.Size([128])\n",
      "fc2.weight shape: torch.Size([1, 128])\n",
      "fc2.bias shape: torch.Size([1])\n",
      "\n",
      "Fully Connected Classifier Layers:\n",
      "weight shape: torch.Size([2, 1280])\n",
      "bias shape: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dummy input parameters\n",
    "batch_size = 2       # Number of videos in a batch\n",
    "num_frames = 10      # Number of frames per video\n",
    "channels = 3         # RGB channels\n",
    "height = 224         # Frame height\n",
    "width = 224          # Frame width\n",
    "num_classes = len(CLASSES_LIST)  # Define this based on your class list\n",
    "\n",
    "# Initialize the model\n",
    "model = EfficientNetTemporalAttentionModel(num_classes=num_classes).to(device)\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n",
    "\n",
    "# Create a dummy input tensor\n",
    "dummy_input = torch.randn(batch_size, num_frames, channels, height, width).to(device)\n",
    "\n",
    "# Run a forward pass\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Check output shape\n",
    "print(f\"Output shape: {output.shape}\")  # Expected: (batch_size, num_classes)\n",
    "\n",
    "# Check weights in EfficientNet, Temporal Attention, and Classifier\n",
    "print(\"\\nModel Weights Shapes:\")\n",
    "print(\"\\nEfficientNet Feature Extractor Layers:\")\n",
    "for name, param in model.feature_extractor.named_parameters():\n",
    "    print(f\"{name} shape: {param.shape}\")\n",
    "\n",
    "print(\"\\nTemporal Attention Layers:\")\n",
    "for name, param in model.temporal_attention.named_parameters():\n",
    "    print(f\"{name} shape: {param.shape}\")\n",
    "\n",
    "print(\"\\nFully Connected Classifier Layers:\")\n",
    "for name, param in model.fc.named_parameters():\n",
    "    print(f\"{name} shape: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.25, shuffle=True)\n",
    "\n",
    "features_train = torch.tensor(features_train).float().permute(0, 1, 4, 2, 3).to(device)  \n",
    "features_test = torch.tensor(features_test).float().permute(0, 1, 4, 2, 3).to(device)\n",
    "labels_train = torch.tensor(labels_train).long().to(device)\n",
    "labels_test = torch.tensor(labels_test).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = VideoDataset(features_train, labels_train)\n",
    "test_dataset = VideoDataset(features_test, labels_test)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/53 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 106.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m, in \u001b[0;36mEfficientNetTemporalAttentionModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     31\u001b[0m batch_size, num_frames, channels, height, width \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m     33\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(batch_size \u001b[38;5;241m*\u001b[39m num_frames, channels, height, width)  \n\u001b[1;32m---> 34\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     35\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(batch_size, num_frames, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n\u001b[0;32m     36\u001b[0m attended_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attention(features)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._call_impl at line 1562 (1 times), Module._wrapped_call_impl at line 1553 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[0;32m    166\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:405\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\finalenv\\Lib\\site-packages\\torch\\nn\\functional.py:2104\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 3.28 GiB is allocated by PyTorch, and 106.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = EfficientNetTemporalAttentionModel(num_classes=len(CLASSES_LIST)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
    "        for inputs, labels in train_loader:\n",
    "            # Move data to the device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get predictions and update accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.set_postfix(loss=running_loss / (pbar.n + 1), accuracy=100. * correct / total if total > 0 else 0)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Print loss and accuracy at the end of the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_accuracy = 100. * correct / total if total > 0 else 0  # Avoid division by zero\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100.*correct/total}%\")\n",
    "\n",
    "# Save the Model\n",
    "torch.save(model.state_dict(), \"ConvLSTM_Test3.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
